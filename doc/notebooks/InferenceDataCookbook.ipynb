{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference Data Cookbook\n",
    "`InferenceData` is the central data format for ArviZ. `InferenceData` itself is just a container that maintains references to one or more `xarray.Dataset`. Below are various ways to generate an `InferenceData` object. See [here](XarrayforArviZ.ipynb) for more on xarray."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From 1d numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference data with groups:\n",
      "\t> posterior\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:  (chain: 1, draw: 100)\n",
       "Coordinates:\n",
       "  * chain    (chain) int64 0\n",
       "  * draw     (draw) int64 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 ...\n",
       "Data variables:\n",
       "    x        (chain, draw) float64 -0.8813 0.3384 1.384 1.241 0.5025 -0.564 ..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size = 100\n",
    "dataset = az.convert_to_inference_data(np.random.randn(size))\n",
    "print(dataset)\n",
    "dataset.posterior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From nd numpy array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference data with groups:\n",
      "\t> posterior\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:  (chain: 1, draw: 2, x_dim_0: 3, x_dim_1: 4, x_dim_2: 5)\n",
       "Coordinates:\n",
       "  * chain    (chain) int64 0\n",
       "  * draw     (draw) int64 0 1\n",
       "  * x_dim_0  (x_dim_0) int64 0 1 2\n",
       "  * x_dim_1  (x_dim_1) int64 0 1 2 3\n",
       "  * x_dim_2  (x_dim_2) int64 0 1 2 3 4\n",
       "Data variables:\n",
       "    x        (chain, draw, x_dim_0, x_dim_1, x_dim_2) float64 0.2366 -2.062 ..."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape = (1, 2, 3, 4, 5)\n",
    "dataset = az.convert_to_inference_data(np.random.randn(*shape))\n",
    "print(dataset)\n",
    "dataset.posterior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference data with groups:\n",
      "\t> posterior\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:  (b_dim_0: 10, c_dim_0: 3, c_dim_1: 4, chain: 1, draw: 100)\n",
       "Coordinates:\n",
       "  * chain    (chain) int64 0\n",
       "  * draw     (draw) int64 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 ...\n",
       "  * b_dim_0  (b_dim_0) int64 0 1 2 3 4 5 6 7 8 9\n",
       "  * c_dim_0  (c_dim_0) int64 0 1 2\n",
       "  * c_dim_1  (c_dim_1) int64 0 1 2 3\n",
       "Data variables:\n",
       "    a        (chain, draw) float64 -3.45 -0.9621 0.5625 -0.9328 -0.1887 ...\n",
       "    b        (chain, draw, b_dim_0) float64 0.7919 0.2132 0.6567 0.3348 ...\n",
       "    c        (chain, draw, c_dim_0, c_dim_1) float64 0.2097 -0.4977 0.8485 ..."
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datadict = {\n",
    "    'a': np.random.randn(100),\n",
    "    'b': np.random.randn(1, 100, 10),\n",
    "    'c': np.random.randn(1, 100, 3, 4),\n",
    "}\n",
    "dataset = az.convert_to_inference_data(datadict)\n",
    "print(dataset)\n",
    "dataset.posterior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From dictionary with coords and dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference data with groups:\n",
      "\t> posterior\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:  (b1: 10, c1: 3, c2: 4, chain: 1, draw: 100)\n",
       "Coordinates:\n",
       "  * chain    (chain) int64 0\n",
       "  * draw     (draw) int64 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 ...\n",
       "  * b1       (b1) int64 0 1 2 3 4 5 6 7 8 9\n",
       "  * c1       (c1) int64 0 1 2\n",
       "  * c2       (c2) int64 0 1 2 3\n",
       "Data variables:\n",
       "    a        (chain, draw) float64 -1.477 0.7551 0.2976 -0.5388 -0.05706 ...\n",
       "    b        (chain, draw, b1) float64 -1.669 -0.8185 0.4427 -1.23 0.8002 ...\n",
       "    c        (chain, draw, c1, c2) float64 -0.5959 -0.8583 0.5428 1.132 ..."
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datadict = {\n",
    "    'a': np.random.randn(100),\n",
    "    'b': np.random.randn(1, 100, 10),\n",
    "    'c': np.random.randn(1, 100, 3, 4),\n",
    "}\n",
    "coords = {'c1' : np.arange(3), 'c2' : np.arange(4), 'b1' : np.arange(10)}\n",
    "dims = {'b' : ['b1'], 'c' : ['c1', 'c2']}\n",
    "\n",
    "dataset = az.convert_to_inference_data(datadict, coords=coords, dims=dims)\n",
    "print(dataset)\n",
    "dataset.posterior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From pymc3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "INFO:pymc3:Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "INFO:pymc3:Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (2 chains in 4 jobs)\n",
      "INFO:pymc3:Multiprocess sampling (2 chains in 4 jobs)\n",
      "NUTS: [theta_tilde, tau, mu]\n",
      "INFO:pymc3:NUTS: [theta_tilde, tau, mu]\n",
      "Sampling 2 chains: 100%|██████████| 2000/2000 [00:00<00:00, 2253.54draws/s]\n",
      "There were 3 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "ERROR:pymc3:There were 3 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "100%|██████████| 500/500 [00:00<00:00, 3327.88it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Inference data with groups:\n",
       "\t> posterior\n",
       "\t> sample_stats\n",
       "\t> posterior_predictive\n",
       "\t> prior\n",
       "\t> observed_data"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pymc3 as pm\n",
    "draws = 500\n",
    "chains = 2\n",
    "\n",
    "eight_school_data = {'J': 8,\n",
    "                     'y': np.array([28., 8., -3., 7., -1., 1., 18., 12.]),\n",
    "                     'sigma': np.array([15., 10., 16., 11., 9., 11., 10., 18.])\n",
    "                    }\n",
    "\n",
    "with pm.Model() as model:\n",
    "    mu = pm.Normal('mu', mu=0, sd=5)\n",
    "    tau = pm.HalfCauchy('tau', beta=5)\n",
    "    theta_tilde = pm.Normal('theta_tilde', mu=0, sd=1, shape=eight_school_data['J'])\n",
    "    theta = pm.Deterministic('theta', mu + tau * theta_tilde)\n",
    "    pm.Normal('obs', mu=theta, sd=eight_school_data['sigma'], observed=eight_school_data['y'])\n",
    "    \n",
    "    trace = pm.sample(draws, chains=chains)\n",
    "    prior = pm.sample_prior_predictive()\n",
    "    posterior_predictive = pm.sample_posterior_predictive(trace, 500, model)\n",
    "    \n",
    "    data = az.from_pymc3(\n",
    "            trace=trace,\n",
    "            prior=prior,\n",
    "            posterior_predictive=posterior_predictive,\n",
    "            coords={'school': np.arange(eight_school_data['J'])},\n",
    "            dims={'theta': ['school'], 'theta_tilde': ['school']},\n",
    "        )\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From pystan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:64 of 1000 iterations ended with a divergence (6.4%).\n",
      "WARNING:pystan:Try running with adapt_delta larger than 0.8 to remove the divergences.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Inference data with groups:\n",
       "\t> posterior\n",
       "\t> sample_stats\n",
       "\t> posterior_predictive\n",
       "\t> observed_data"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pystan\n",
    "schools_code = '''\n",
    "        data {\n",
    "            int<lower=0> J;\n",
    "            real y[J];\n",
    "            real<lower=0> sigma[J];\n",
    "        }\n",
    "\n",
    "        parameters {\n",
    "            real mu;\n",
    "            real<lower=0> tau;\n",
    "            real theta_tilde[J];\n",
    "        }\n",
    "\n",
    "        transformed parameters {\n",
    "            real theta[J];\n",
    "            for (j in 1:J)\n",
    "                theta[j] = mu + tau * theta_tilde[j];\n",
    "        }\n",
    "\n",
    "        model {\n",
    "            mu ~ normal(0, 5);\n",
    "            tau ~ cauchy(0, 5);\n",
    "            theta_tilde ~ normal(0, 1);\n",
    "            y ~ normal(theta, sigma);\n",
    "        }\n",
    "\n",
    "        generated quantities {\n",
    "            vector[J] log_lik;\n",
    "            vector[J] y_hat;\n",
    "            for (j in 1:J) {\n",
    "                log_lik[j] = normal_lpdf(y[j] | theta[j], sigma[j]);\n",
    "                y_hat[j] = normal_rng(theta[j], sigma[j]);\n",
    "            }\n",
    "        }\n",
    "    '''\n",
    "stan_model = pystan.StanModel(model_code=schools_code)\n",
    "fit = stan_model.sampling(data=eight_school_data,\n",
    "                          iter=draws,\n",
    "                          warmup=0,\n",
    "                          chains=chains)\n",
    "\n",
    "data = az.from_pystan(fit=fit,\n",
    "                      posterior_predictive='y_hat',\n",
    "                      observed_data=['y'],\n",
    "                      log_likelihood='log_lik',\n",
    "                      coords={'school': np.arange(eight_school_data['J'])},\n",
    "                      dims={'theta': ['school'],\n",
    "                             'y': ['school'],\n",
    "                             'log_lik': ['school'],\n",
    "                             'y_hat': ['school'],\n",
    "                             'theta_tilde': ['school']\n",
    "                            }\n",
    "                     )\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From pyro\n",
    "See [from_pyro](https://arviz-devs.github.io/arviz/generated/arviz.from_pyro.html#arviz.from_pyro) for details. Cookbook documentation coming soon.\n",
    "\n",
    "## From emcee\n",
    "See [from_emcee](https://arviz-devs.github.io/arviz/generated/arviz.from_emcee.html#arviz.from_emcee) for details. Cookbook documentation coming soon.\n",
    "\n",
    "\n",
    "## From cmdstan\n",
    "See [from_cmdstan](https://arviz-devs.github.io/arviz/generated/arviz.from_cmdstan.html#arviz.from_cmdstan) for details. Cookbook documentation coming soon.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
