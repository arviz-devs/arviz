{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference Data Cookbook\n",
    "`InferenceData` is the central data format for ArviZ. `InferenceData` itself is just a container that maintains references to one or more `xarray.Dataset`. Below are various ways to generate an `InferenceData` object. See [here](XarrayforArviZ.ipynb) for more on xarray."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From 1d numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference data with groups:\n",
      "\t> posterior\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:  (chain: 1, draw: 100)\n",
       "Coordinates:\n",
       "  * chain    (chain) int64 0\n",
       "  * draw     (draw) int64 0 1 2 3 4 5 6 7 8 9 ... 90 91 92 93 94 95 96 97 98 99\n",
       "Data variables:\n",
       "    x        (chain, draw) float64 1.084 -0.5994 -0.894 ... 2.022 2.334 0.0274\n",
       "Attributes:\n",
       "    created_at:  2019-06-21T16:57:30.377550"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size = 100\n",
    "dataset = az.convert_to_inference_data(np.random.randn(size))\n",
    "print(dataset)\n",
    "dataset.posterior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From nd numpy array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference data with groups:\n",
      "\t> posterior\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:  (chain: 1, draw: 2, x_dim_0: 3, x_dim_1: 4, x_dim_2: 5)\n",
       "Coordinates:\n",
       "  * chain    (chain) int64 0\n",
       "  * draw     (draw) int64 0 1\n",
       "  * x_dim_0  (x_dim_0) int64 0 1 2\n",
       "  * x_dim_1  (x_dim_1) int64 0 1 2 3\n",
       "  * x_dim_2  (x_dim_2) int64 0 1 2 3 4\n",
       "Data variables:\n",
       "    x        (chain, draw, x_dim_0, x_dim_1, x_dim_2) float64 -0.6808 ... -0.8528\n",
       "Attributes:\n",
       "    created_at:  2019-06-21T16:57:30.825192"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape = (1, 2, 3, 4, 5)\n",
    "dataset = az.convert_to_inference_data(np.random.randn(*shape))\n",
    "print(dataset)\n",
    "dataset.posterior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference data with groups:\n",
      "\t> posterior\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:  (b_dim_0: 10, c_dim_0: 3, c_dim_1: 4, chain: 1, draw: 100)\n",
       "Coordinates:\n",
       "  * chain    (chain) int64 0\n",
       "  * draw     (draw) int64 0 1 2 3 4 5 6 7 8 9 ... 90 91 92 93 94 95 96 97 98 99\n",
       "  * b_dim_0  (b_dim_0) int64 0 1 2 3 4 5 6 7 8 9\n",
       "  * c_dim_0  (c_dim_0) int64 0 1 2\n",
       "  * c_dim_1  (c_dim_1) int64 0 1 2 3\n",
       "Data variables:\n",
       "    a        (chain, draw) float64 -1.25 -0.1914 0.08028 ... 0.5569 -0.7766\n",
       "    b        (chain, draw, b_dim_0) float64 -0.8137 1.036 ... 0.2932 -0.8754\n",
       "    c        (chain, draw, c_dim_0, c_dim_1) float64 0.32 -0.004118 ... -0.3479\n",
       "Attributes:\n",
       "    created_at:  2019-06-21T16:57:31.544505"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datadict = {\n",
    "    'a': np.random.randn(100),\n",
    "    'b': np.random.randn(1, 100, 10),\n",
    "    'c': np.random.randn(1, 100, 3, 4),\n",
    "}\n",
    "dataset = az.convert_to_inference_data(datadict)\n",
    "print(dataset)\n",
    "dataset.posterior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From dictionary with coords and dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference data with groups:\n",
      "\t> posterior\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:  (b1: 10, c1: 3, c2: 4, chain: 1, draw: 100)\n",
       "Coordinates:\n",
       "  * chain    (chain) int64 0\n",
       "  * draw     (draw) int64 0 1 2 3 4 5 6 7 8 9 ... 90 91 92 93 94 95 96 97 98 99\n",
       "  * b1       (b1) int64 0 1 2 3 4 5 6 7 8 9\n",
       "  * c1       (c1) int64 0 1 2\n",
       "  * c2       (c2) int64 0 1 2 3\n",
       "Data variables:\n",
       "    a        (chain, draw) float64 1.697 -0.4425 0.3771 ... 1.135 -0.469 2.276\n",
       "    b        (chain, draw, b1) float64 -0.2085 0.3442 0.2856 ... 0.2459 -1.886\n",
       "    c        (chain, draw, c1, c2) float64 0.9242 -0.8723 ... -2.333 -0.5566\n",
       "Attributes:\n",
       "    created_at:  2019-06-21T16:57:32.498636"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datadict = {\n",
    "    'a': np.random.randn(100),\n",
    "    'b': np.random.randn(1, 100, 10),\n",
    "    'c': np.random.randn(1, 100, 3, 4),\n",
    "}\n",
    "coords = {\n",
    "    'c1' : np.arange(3), \n",
    "    'c2' : np.arange(4), \n",
    "    'b1' : np.arange(10)\n",
    "}\n",
    "dims = {\n",
    "    'b' : ['b1'], \n",
    "    'c' : ['c1', 'c2']\n",
    "}\n",
    "\n",
    "dataset = az.convert_to_inference_data(\n",
    "    datadict,\n",
    "    coords=coords,\n",
    "    dims=dims\n",
    ")\n",
    "print(dataset)\n",
    "dataset.posterior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From pymc3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (2 chains in 4 jobs)\n",
      "NUTS: [theta_tilde, tau, mu]\n",
      "Sampling 2 chains: 100%|██████████| 2000/2000 [00:00<00:00, 2197.77draws/s]\n",
      "There were 3 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There was 1 divergence after tuning. Increase `target_accept` or reparameterize.\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 2134.56it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Inference data with groups:\n",
       "\t> posterior\n",
       "\t> sample_stats\n",
       "\t> posterior_predictive\n",
       "\t> prior\n",
       "\t> observed_data"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pymc3 as pm\n",
    "draws = 500\n",
    "chains = 2\n",
    "\n",
    "eight_school_data = {\n",
    "    'J': 8,\n",
    "    'y': np.array([28., 8., -3., 7., -1., 1., 18., 12.]),\n",
    "    'sigma': np.array([15., 10., 16., 11., 9., 11., 10., 18.])\n",
    "}\n",
    "\n",
    "with pm.Model() as model:\n",
    "    mu = pm.Normal('mu', mu=0, sd=5)\n",
    "    tau = pm.HalfCauchy('tau', beta=5)\n",
    "    theta_tilde = pm.Normal('theta_tilde', mu=0, sd=1, shape=eight_school_data['J'])\n",
    "    theta = pm.Deterministic('theta', mu + tau * theta_tilde)\n",
    "    pm.Normal('obs', mu=theta, sd=eight_school_data['sigma'], observed=eight_school_data['y'])\n",
    "    \n",
    "    trace = pm.sample(draws, chains=chains)\n",
    "    prior = pm.sample_prior_predictive()\n",
    "    posterior_predictive = pm.sample_posterior_predictive(trace)\n",
    "    \n",
    "    pm_data = az.from_pymc3(\n",
    "            trace=trace,\n",
    "            prior=prior,\n",
    "            posterior_predictive=posterior_predictive,\n",
    "            coords={'school': np.arange(eight_school_data['J'])},\n",
    "            dims={'theta': ['school'], 'theta_tilde': ['school']},\n",
    "        )\n",
    "pm_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From pystan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Inference data with groups:\n",
       "\t> posterior\n",
       "\t> sample_stats\n",
       "\t> posterior_predictive\n",
       "\t> observed_data"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pystan\n",
    "\n",
    "schools_code = \"\"\"\n",
    "data {\n",
    "    int<lower=0> J;\n",
    "    real y[J];\n",
    "    real<lower=0> sigma[J];\n",
    "}\n",
    "\n",
    "parameters {\n",
    "    real mu;\n",
    "    real<lower=0> tau;\n",
    "    real theta_tilde[J];\n",
    "}\n",
    "\n",
    "transformed parameters {\n",
    "    real theta[J];\n",
    "    for (j in 1:J)\n",
    "        theta[j] = mu + tau * theta_tilde[j];\n",
    "}\n",
    "\n",
    "model {\n",
    "    mu ~ normal(0, 5);\n",
    "    tau ~ cauchy(0, 5);\n",
    "    theta_tilde ~ normal(0, 1);\n",
    "    y ~ normal(theta, sigma);\n",
    "}\n",
    "\n",
    "generated quantities {\n",
    "    vector[J] log_lik;\n",
    "    vector[J] y_hat;\n",
    "    for (j in 1:J) {\n",
    "        log_lik[j] = normal_lpdf(y[j] | theta[j], sigma[j]);\n",
    "        y_hat[j] = normal_rng(theta[j], sigma[j]);\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "eight_school_data = {\n",
    "    'J': 8,\n",
    "    'y': np.array([28., 8., -3., 7., -1., 1., 18., 12.]),\n",
    "    'sigma': np.array([15., 10., 16., 11., 9., 11., 10., 18.])\n",
    "}\n",
    "\n",
    "stan_model = pystan.StanModel(model_code=schools_code)\n",
    "fit = stan_model.sampling(data=eight_school_data, control={\"adapt_delta\" : 0.9})\n",
    "\n",
    "stan_data = az.from_pystan(\n",
    "    posterior=fit,\n",
    "    posterior_predictive='y_hat',\n",
    "    observed_data=['y'],\n",
    "    log_likelihood='log_lik',\n",
    "    coords={'school': np.arange(eight_school_data['J'])},\n",
    "    dims={\n",
    "        'theta': ['school'],\n",
    "        'y': ['school'],\n",
    "        'log_lik': ['school'],\n",
    "        'y_hat': ['school'],\n",
    "        'theta_tilde': ['school']\n",
    "    }\n",
    ")\n",
    "\n",
    "stan_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From pyro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pyro.infer.mcmc.mcmc:Starting MCMC using kernel - NUTS ...\n",
      "INFO:pyro.infer.mcmc.mcmc:Iteration: 50 [SAMPLE]\n",
      "INFO:pyro.infer.mcmc.mcmc:Step size: 0.125390 \t Acceptance rate: 0.860000\n",
      "INFO:pyro.infer.mcmc.mcmc:Iteration: 100 [SAMPLE]\n",
      "INFO:pyro.infer.mcmc.mcmc:Step size: 0.789698 \t Acceptance rate: 0.910000\n",
      "INFO:pyro.infer.mcmc.mcmc:Iteration: 150 [SAMPLE]\n",
      "INFO:pyro.infer.mcmc.mcmc:Step size: 0.282786 \t Acceptance rate: 0.920000\n",
      "INFO:pyro.infer.mcmc.mcmc:Iteration: 200 [SAMPLE]\n",
      "INFO:pyro.infer.mcmc.mcmc:Step size: 0.105557 \t Acceptance rate: 0.930000\n",
      "INFO:pyro.infer.mcmc.mcmc:Iteration: 250 [SAMPLE]\n",
      "INFO:pyro.infer.mcmc.mcmc:Step size: 0.527265 \t Acceptance rate: 0.944000\n",
      "INFO:pyro.infer.mcmc.mcmc:Iteration: 300 [SAMPLE]\n",
      "INFO:pyro.infer.mcmc.mcmc:Step size: 0.200404 \t Acceptance rate: 0.940000\n",
      "INFO:pyro.infer.mcmc.mcmc:Iteration: 350 [SAMPLE]\n",
      "INFO:pyro.infer.mcmc.mcmc:Step size: 0.286618 \t Acceptance rate: 0.945714\n",
      "INFO:pyro.infer.mcmc.mcmc:Iteration: 400 [SAMPLE]\n",
      "INFO:pyro.infer.mcmc.mcmc:Step size: 0.323607 \t Acceptance rate: 0.945000\n",
      "INFO:pyro.infer.mcmc.mcmc:Iteration: 450 [SAMPLE]\n",
      "INFO:pyro.infer.mcmc.mcmc:Step size: 0.600277 \t Acceptance rate: 0.948889\n",
      "INFO:pyro.infer.mcmc.mcmc:Iteration: 500 [SAMPLE]\n",
      "INFO:pyro.infer.mcmc.mcmc:Step size: 0.265936 \t Acceptance rate: 0.950000\n",
      "INFO:pyro.infer.mcmc.mcmc:Iteration: 550 [SAMPLE]\n",
      "INFO:pyro.infer.mcmc.mcmc:Step size: 0.423345 \t Acceptance rate: 0.945455\n",
      "INFO:pyro.infer.mcmc.mcmc:Iteration: 600 [SAMPLE]\n",
      "INFO:pyro.infer.mcmc.mcmc:Step size: 0.675079 \t Acceptance rate: 0.948333\n",
      "INFO:pyro.infer.mcmc.mcmc:Iteration: 650 [SAMPLE]\n",
      "INFO:pyro.infer.mcmc.mcmc:Step size: 0.523993 \t Acceptance rate: 0.949231\n",
      "INFO:pyro.infer.mcmc.mcmc:Iteration: 700 [SAMPLE]\n",
      "INFO:pyro.infer.mcmc.mcmc:Step size: 0.372428 \t Acceptance rate: 0.948571\n",
      "INFO:pyro.infer.mcmc.mcmc:Iteration: 750 [SAMPLE]\n",
      "INFO:pyro.infer.mcmc.mcmc:Step size: 0.536313 \t Acceptance rate: 0.950667\n",
      "INFO:pyro.infer.mcmc.mcmc:Iteration: 800 [SAMPLE]\n",
      "INFO:pyro.infer.mcmc.mcmc:Step size: 0.508929 \t Acceptance rate: 0.948750\n",
      "INFO:pyro.infer.mcmc.mcmc:Iteration: 850 [SAMPLE]\n",
      "INFO:pyro.infer.mcmc.mcmc:Step size: 0.551862 \t Acceptance rate: 0.948235\n",
      "INFO:pyro.infer.mcmc.mcmc:Iteration: 900 [SAMPLE]\n",
      "INFO:pyro.infer.mcmc.mcmc:Step size: 0.283344 \t Acceptance rate: 0.948889\n",
      "INFO:pyro.infer.mcmc.mcmc:Iteration: 950 [SAMPLE]\n",
      "INFO:pyro.infer.mcmc.mcmc:Step size: 0.411292 \t Acceptance rate: 0.950526\n",
      "INFO:pyro.infer.mcmc.mcmc:Iteration: 1000 [SAMPLE]\n",
      "INFO:pyro.infer.mcmc.mcmc:Step size: 0.372683 \t Acceptance rate: 0.950000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Inference data with groups:\n",
       "\t> posterior\n",
       "\t> observed_data"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import pyro.poutine as poutine\n",
    "from pyro.infer.mcmc import MCMC, NUTS\n",
    "\n",
    "pyro.enable_validation(True)\n",
    "pyro.set_rng_seed(0)\n",
    "\n",
    "draws = 1000\n",
    "warmup_steps = 0\n",
    "eight_school_data = {\n",
    "    'J': 8,\n",
    "    'y': np.array([28., 8., -3., 7., -1., 1., 18., 12.]),\n",
    "    'sigma': np.array([15., 10., 16., 11., 9., 11., 10., 18.])\n",
    "}\n",
    "\n",
    "\n",
    "def model(sigma):\n",
    "    eta = pyro.sample('eta', dist.Normal(torch.zeros(eight_school_data['J']), torch.ones(eight_school_data['J'])))\n",
    "    mu = pyro.sample('mu', dist.Normal(torch.zeros(1), 10 * torch.ones(1)))\n",
    "    tau = pyro.sample('tau', dist.HalfCauchy(scale=25 * torch.ones(1)))\n",
    "\n",
    "    theta = mu + tau * eta\n",
    "\n",
    "    return pyro.sample(\"obs\", dist.Normal(theta, sigma))\n",
    "\n",
    "\n",
    "def conditioned_model(model, sigma, y):\n",
    "    return poutine.condition(model, data={\"obs\": y})(sigma)\n",
    "\n",
    "\n",
    "\n",
    "nuts_kernel = NUTS(conditioned_model, adapt_step_size=True)\n",
    "posterior = MCMC(nuts_kernel,\n",
    "                 num_samples=draws,\n",
    "                 warmup_steps=warmup_steps).run(model, eight_school_data['sigma'], eight_school_data['y'])\n",
    "\n",
    "pyro_data = az.from_pyro(posterior)\n",
    "pyro_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From emcee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Inference data with groups:\n",
       "\t> posterior\n",
       "\t> observed_data"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import emcee\n",
    "\n",
    "eight_school_data = {\n",
    "    'J': 8,\n",
    "    'y': np.array([28., 8., -3., 7., -1., 1., 18., 12.]),\n",
    "    'sigma': np.array([15., 10., 16., 11., 9., 11., 10., 18.])\n",
    "}\n",
    "\n",
    "def log_prior_8school(theta,J):\n",
    "    mu = theta[0]\n",
    "    tau = theta[1]\n",
    "    eta = theta[2:]\n",
    "    # Half-cauchy prior\n",
    "    if tau<0:\n",
    "        return -np.inf\n",
    "    hwhm = 25\n",
    "    prior_tau = -np.log(tau**2+hwhm**2)\n",
    "    prior_mu = -(mu/10)**2  # normal prior, loc=0, scale=10\n",
    "    prior_eta = -np.sum(eta**2)  # normal prior, loc=0, scale=1\n",
    "    return prior_mu + prior_tau + prior_eta\n",
    "    \n",
    "def log_likelihood_8school(theta,y,sigma):\n",
    "    mu = theta[0]\n",
    "    tau = theta[1]\n",
    "    eta = theta[2:]\n",
    "    return -np.sum(((mu + tau * eta - y) / sigma)**2)\n",
    "    \n",
    "def lnprob_8school(theta,J,y,sigma):\n",
    "    prior = log_prior_8school(theta,J)\n",
    "    if prior <= -np.inf:\n",
    "        return -np.inf\n",
    "    like = log_likelihood_8school(theta,y,sigma)\n",
    "    return like+prior\n",
    "\n",
    "nwalkers = 40\n",
    "ndim = eight_school_data['J']+2\n",
    "draws = 1500\n",
    "pos = np.random.normal(size=(nwalkers,ndim))\n",
    "pos[:,1] = np.absolute(pos[:,1])\n",
    "sampler = emcee.EnsembleSampler(nwalkers, \n",
    "                                ndim, \n",
    "                                lnprob_8school, \n",
    "                                args=(eight_school_data['J'], \n",
    "                                      eight_school_data['y'], \n",
    "                                      eight_school_data['sigma']\n",
    "                                     )\n",
    "                               )\n",
    "sampler.run_mcmc(pos, draws)\n",
    "\n",
    "# define variable names, it cannot be inferred from emcee\n",
    "var_names = ['mu','tau']+['eta{}'.format(i) for i in range(eight_school_data['J'])]\n",
    "emcee_data = az.from_emcee(sampler, var_names = var_names)\n",
    "emcee_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From CmdStanPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cmdstanpy:stan to c++ (eight_school.hpp)\n",
      "INFO:cmdstanpy:compiling c++\n",
      "INFO:cmdstanpy:compiled model file: ./eight_school\n",
      "INFO:cmdstanpy:start chain 1\n",
      "INFO:cmdstanpy:start chain 2\n",
      "INFO:cmdstanpy:finish chain 2\n",
      "INFO:cmdstanpy:start chain 3\n",
      "INFO:cmdstanpy:finish chain 1\n",
      "INFO:cmdstanpy:start chain 4\n",
      "INFO:cmdstanpy:finish chain 3\n",
      "INFO:cmdstanpy:finish chain 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Inference data with groups:\n",
       "\t> posterior\n",
       "\t> sample_stats\n",
       "\t> posterior_predictive\n",
       "\t> observed_data"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cmdstanpy import Model, StanFit\n",
    "\n",
    "schools_code = \"\"\"\n",
    "data {\n",
    "    int<lower=0> J;\n",
    "    real y[J];\n",
    "    real<lower=0> sigma[J];\n",
    "}\n",
    "\n",
    "parameters {\n",
    "    real mu;\n",
    "    real<lower=0> tau;\n",
    "    real theta_tilde[J];\n",
    "}\n",
    "\n",
    "transformed parameters {\n",
    "    real theta[J];\n",
    "    for (j in 1:J)\n",
    "        theta[j] = mu + tau * theta_tilde[j];\n",
    "}\n",
    "\n",
    "model {\n",
    "    mu ~ normal(0, 5);\n",
    "    tau ~ cauchy(0, 5);\n",
    "    theta_tilde ~ normal(0, 1);\n",
    "    y ~ normal(theta, sigma);\n",
    "}\n",
    "\n",
    "generated quantities {\n",
    "    vector[J] log_lik;\n",
    "    vector[J] y_hat;\n",
    "    for (j in 1:J) {\n",
    "        log_lik[j] = normal_lpdf(y[j] | theta[j], sigma[j]);\n",
    "        y_hat[j] = normal_rng(theta[j], sigma[j]);\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "with open(\"./eight_school.stan\", \"w\") as f:\n",
    "    print(schools_code, file=f)\n",
    "\n",
    "stan_file = \"./eight_school.stan\"\n",
    "stan_model = Model(stan_file=stan_file)\n",
    "stan_model.compile()\n",
    "\n",
    "eight_school_data = {'J': 8,\n",
    "                     'y': np.array([28., 8., -3., 7., -1., 1., 18., 12.]),\n",
    "                     'sigma': np.array([15., 10., 16., 11., 9., 11., 10., 18.])\n",
    "                    }\n",
    "\n",
    "stan_fit = stan_model.sample(data=eight_school_data)\n",
    "\n",
    "cmdstanpy_data = az.from_cmdstanpy(\n",
    "    posterior=stan_fit,\n",
    "    posterior_predictive='y_hat',\n",
    "    observed_data={'y' : eight_school_data[\"y\"]},\n",
    "    log_likelihood='log_lik',\n",
    "    coords={'school': np.arange(eight_school_data['J'])},\n",
    "    dims={\n",
    "        'theta': ['school'],\n",
    "        'y': ['school'],\n",
    "        'log_lik': ['school'],\n",
    "        'y_hat': ['school'],\n",
    "        'theta_tilde': ['school']\n",
    "        }\n",
    ")\n",
    "cmdstanpy_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From CmdStan\n",
    "\n",
    "See [from_cmdstan](https://arviz-devs.github.io/arviz/generated/arviz.from_cmdstan.html#arviz.from_cmdstan) for details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CmdStan helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save for CmdStan example (needs CmdStanPy run)\n",
    "stan_fit.save_csvfiles(dir=\"sample_data\", basename=\"eight_school_samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "schools_code = \"\"\"\n",
    "data {\n",
    "    int<lower=0> J;\n",
    "    real y[J];\n",
    "    real<lower=0> sigma[J];\n",
    "}\n",
    "\n",
    "parameters {\n",
    "    real mu;\n",
    "    real<lower=0> tau;\n",
    "    real theta_tilde[J];\n",
    "}\n",
    "\n",
    "transformed parameters {\n",
    "    real theta[J];\n",
    "    for (j in 1:J)\n",
    "        theta[j] = mu + tau * theta_tilde[j];\n",
    "}\n",
    "\n",
    "model {\n",
    "    mu ~ normal(0, 5);\n",
    "    tau ~ cauchy(0, 5);\n",
    "    theta_tilde ~ normal(0, 1);\n",
    "    y ~ normal(theta, sigma);\n",
    "}\n",
    "\n",
    "generated quantities {\n",
    "    vector[J] log_lik;\n",
    "    vector[J] y_hat;\n",
    "    for (j in 1:J) {\n",
    "        log_lik[j] = normal_lpdf(y[j] | theta[j], sigma[j]);\n",
    "        y_hat[j] = normal_rng(theta[j], sigma[j]);\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "with open(\"./eight_school.stan\", \"w\") as f:\n",
    "    print(schools_code, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "eight_school_data = {\n",
    "    'J': 8,\n",
    "    'y': np.array([28., 8., -3., 7., -1., 1., 18., 12.]),\n",
    "    'sigma': np.array([15., 10., 16., 11., 9., 11., 10., 18.])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pystan\n",
    "pystan.stan_rdump(eight_school_data, \"./eight_school.data.R\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bash shell\n",
    "#\n",
    "# $ cd cmdstan\n",
    "# $ make build\n",
    "# $ make path/to/eight_school\n",
    "# $ cd path/to\n",
    "# $ for i in {1..4}\n",
    "#   do\n",
    "#     ./eight_school sample random seed=12345 \\\n",
    "#       id=$i data file=eight_school.data.R \\\n",
    "#       output file=sample_data/eight_school_samples-$i.csv &\n",
    "#   done\n",
    "# $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "arviz.data.io_cmdstan - INFO - glob found 4 files for 'posterior':\n",
      "1: sample_data/eight_school_samples-1.csv\n",
      "2: sample_data/eight_school_samples-2.csv\n",
      "3: sample_data/eight_school_samples-3.csv\n",
      "4: sample_data/eight_school_samples-4.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Inference data with groups:\n",
       "\t> posterior\n",
       "\t> sample_stats\n",
       "\t> posterior_predictive\n",
       "\t> observed_data"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's use .stan and .csv files created/saved by the CmdStanPy procedure\n",
    "\n",
    "# glob string\n",
    "posterior_glob =  \"sample_data/eight_school_samples-[0-9].csv\"\n",
    "# list of paths\n",
    "# posterior_list =  [\n",
    "#     \"sample_data/eight_school_samples-1.csv\",\n",
    "#     \"sample_data/eight_school_samples-2.csv\",\n",
    "#     \"sample_data/eight_school_samples-3.csv\",\n",
    "#     \"sample_data/eight_school_samples-4.csv\",\n",
    "# ]\n",
    "\n",
    "obs_data_path = \"./eight_school.data.R\"\n",
    "\n",
    "cmdstan_data = az.from_cmdstan(\n",
    "    posterior = posterior_glob,\n",
    "    posterior_predictive='y_hat',\n",
    "    observed_data=obs_data_path,\n",
    "    observed_data_var=\"y\",\n",
    "    log_likelihood='log_lik',\n",
    "    coords={'school': np.arange(eight_school_data['J'])},\n",
    "    dims={'theta': ['school'],\n",
    "          'y': ['school'],\n",
    "          'log_lik': ['school'],\n",
    "          'y_hat': ['school'],\n",
    "          'theta_tilde': ['school']\n",
    "         }\n",
    ")\n",
    "cmdstan_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From NumPyro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Inference data with groups:\n",
       "\t> posterior\n",
       "\t> sample_stats\n",
       "\t> posterior_predictive"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "# enable 4 CPU cores to draw chains in parallel\n",
    "os.environ['XLA_FLAGS'] = '--xla_force_host_platform_device_count=4'\n",
    "\n",
    "import jax\n",
    "jax.config.update('jax_platform_name', 'cpu')\n",
    "\n",
    "import numpyro\n",
    "import numpyro.distributions as dist\n",
    "from numpyro.distributions.constraints import AffineTransform\n",
    "from numpyro.infer_util import predictive\n",
    "from numpyro.mcmc import MCMC, NUTS\n",
    "\n",
    "eight_school_data = {\n",
    "    'J': 8,\n",
    "    'y': np.array([28., 8., -3., 7., -1., 1., 18., 12.]),\n",
    "    'sigma': np.array([15., 10., 16., 11., 9., 11., 10., 18.])\n",
    "}\n",
    "\n",
    "def model(data):\n",
    "    mu = numpyro.sample('mu', dist.Normal(0, 5))\n",
    "    tau = numpyro.sample('tau', dist.HalfCauchy(5))\n",
    "    # use non-centered reparameterization\n",
    "    theta = numpyro.sample('theta', dist.TransformedDistribution(\n",
    "        dist.Normal(np.zeros(data['J']), 1), AffineTransform(mu, tau)))\n",
    "    numpyro.sample('y', dist.Normal(theta, data['sigma']), obs=data['y'])\n",
    "\n",
    "kernel = NUTS(model)\n",
    "mcmc = MCMC(kernel, num_warmup=500, num_samples=500, num_chains=4, chain_method='parallel')\n",
    "mcmc.run(jax.random.PRNGKey(0), eight_school_data, collect_fields=('z', 'num_steps'))\n",
    "posterior_samples = mcmc.get_samples()[0]\n",
    "posterior_predictive = predictive(\n",
    "    jax.random.PRNGKey(1), model, posterior_samples, ('y',), eight_school_data)\n",
    "\n",
    "numpyro_data = az.from_numpyro(mcmc, posterior_predictive=posterior_predictive,\n",
    "                               coords={'school': np.arange(eight_school_data['J'])},\n",
    "                               dims={'theta': ['school']})\n",
    "numpyro_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
