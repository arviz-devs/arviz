{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91f05010-b82d-42f3-b882-4f689eaa946c",
   "metadata": {},
   "source": [
    "(migration_guide)=\n",
    "# ArviZ migration guide\n",
    "\n",
    "We have been working on refactoring ArviZ to allow more flexibility and extensibility of its elements\n",
    "while keeping as much as possible a friendly user-interface that gives sensible results with little to no arguments.\n",
    "\n",
    "One important change is enhanced modularity. Everything will still be available through a common namespace `arviz`,\n",
    "but ArviZ will now be composed of 3 smaller libraries:\n",
    "\n",
    "* [arviz-base](https://arviz-base.readthedocs.io/en/latest/) data related functionality, including converters from different PPLs.\n",
    "* [arviz-stats](https://arviz-stats.readthedocs.io/en/latest/) for statistical functions and diagnostics.\n",
    "* [arviz-plots](https://arviz-plots.readthedocs.io/en/latest/) for visual checks built on top of arviz-stats and arviz-base.\n",
    "\n",
    "Each library depends only on a minimal set of libraries, with a lot of functionality built on top of optional dependencies.\n",
    "This keeps ArviZ smaller and easier to install as you can install only the components you really need. The main examples are:\n",
    "\n",
    "* `arviz-base` has no I/O library as a dependency, but you can use `netcdf4`, `h5netcdf` or `zarr` to read and write your data, allowing you to install only the one you need.\n",
    "* `arviz-plots` has no plotting library as a dependency, but it can generate plots with `matplotlib`, `bokeh` or `plotly` if they are installed.\n",
    "\n",
    "At the time of writing, `arviz-xyz` libraries are independent of the `arviz` library, but `arviz` tries to import the `arviz-xyz` libraries\n",
    "and exposes all their elements through the `arviz.preview` namespace. In the future, with the ArviZ 1.0 release, the `arviz` namespace will look\n",
    "like `arviz.preview` looks like today.\n",
    "\n",
    "We encourage you to try it out and get a head start on the migration!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4074f836-233b-4b10-8483-d2177cad7424",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz.preview as az\n",
    "# change to import arviz as az after ArviZ 1.0 release"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28ab6bd-d3c1-4f71-981f-3444f39ee249",
   "metadata": {},
   "source": [
    "Check all 3 libraries have been exposed correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c792e9f-9a22-4ba0-ad11-138fbc510784",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(az.info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba357f5-cc19-4fe3-918c-6a540723c3e9",
   "metadata": {},
   "source": [
    "## `arviz-base`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f0a3a9",
   "metadata": {},
   "source": [
    "### Credible intervals and rcParams\n",
    "\n",
    "Some global configuration settings have changed. For example, the default credible interval probability (`ci_prob`) has been updated from 0.94 to 0.89. Using 0.89 produces intervals with lower variability, leading to more stable summaries. At the same time, keeping a non-standard value (rather than 0.90 or 0.95) serves as a friendly reminder that the choice of interval should reflect the problem at hand.\n",
    "\n",
    "In addition, a new setting `ci_kind` has been introduced, which defaults to \"eti\" (equal-tailed interval). This controls the method used to compute credible intervals. The alternative is \"hdi\" (highest density interval), which was previously the default.\n",
    "\n",
    "Defaults set via `rcParams` are not fixed rules, theyâ€™re meant to be adjusted to fit the needs of your analysis. `rcParams` offers a convenient way to establish global defaults for your workflow, while most functions that compute credible intervals also provide `ci_prob` and `ci_kind` arguments to override these settings locally.\n",
    "\n",
    "\n",
    "You can check all defatult settings with:\n",
    "\n",
    "```python\n",
    "az.rcParams\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73c5b99-234c-4b5d-ab3e-adfce2fb2edc",
   "metadata": {},
   "source": [
    "### `DataTree`\n",
    "One of the main differences is the `arviz.InferenceData` object doesn't exist any more.\n",
    "`arviz-base` uses `xarray.DataTree` instead. This is a new data structure in xarray,\n",
    "so it might still have some rough edges, but it is much more flexible and powerful.\n",
    "To give some examples, I/O will now be more flexible, and any format supported by\n",
    "xarray is automatically available to you, no need to add wrappers on top of them within ArviZ.\n",
    "It is also possible to have arbitrary nesting of variables within groups and subgroups.\n",
    "\n",
    ":::{important}\n",
    "Not all the functionality on `xarray.DataTree` will be compatible with ArviZ as it would be too much\n",
    "work for us to cover and maintain. If there are things you have always wanted to do but\n",
    "were not possible with `InferenceData` and are now possible with `DataTree` please try\n",
    "them out, give feedback on them and on desired behaviour for things that still don't work.\n",
    "After a couple releases the \"ArviZverse\" will stabilize much more and it might not be\n",
    "possible to add support for that anymore.\n",
    ":::\n",
    "\n",
    "#### I already have `InferenceData` object from an external library\n",
    "`InferenceData` already has a method to convert it to DataTree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b8a1a1-3f90-497e-9321-2dbf9872541b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as arviz_legacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d579b2-d178-46f1-bc87-5bb8d2db28b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "idata = arviz_legacy.load_arviz_data(\"centered_eight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd60b96-bb57-4859-b829-7a0fa7879b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "idata.to_datatree()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236f1871-444a-4771-ab5b-ca95c78a80f2",
   "metadata": {},
   "source": [
    "#### What about my existing netcdf/zarr files?\n",
    "They are still valid. There have been no changes on this end and don't plan to make any.\n",
    "The only difference is which function handles I/O. There used to be functions\n",
    "in the main arviz namespace like `arviz.from_zarr` and methods to `InferenceData`\n",
    "such as `.to_netcdf`. These are now part of xarray itself:\n",
    "\n",
    "| Function in legacy ArviZ | New equivalent in xarray |\n",
    "|--------------------------|--------------------------|\n",
    "| arviz.from_netcdf        | {func}`xarray.open_datatree`[^1] |\n",
    "| arviz.from_zarr          | {func}`xarray.open_datatree`[^1] |\n",
    "| arviz.to_netcdf          | -                                |\n",
    "| arviz.to_zarr            | -                                |\n",
    "| arviz.InferenceData.from_netcdf | -                                 |\n",
    "| arviz.InferenceData.from_zarr   | -                                 |\n",
    "| arviz.InferenceData.to_netcdf   | {meth}`xarray.DataTree.to_netcdf` |\n",
    "| arviz.InferenceData.to_zarr     | {meth}`xarray.DataTree.to_zarr`   |\n",
    "\n",
    "[^1]: `open_datatree` takes an `engine` argument. Engines \"netcdf4\" (default if installed)\n",
    "    and \"h5netcdf\" allow reading netCDF4 files. Engine \"zarr\" should be used to read zarr files.\n",
    "\n",
    "Here is an example where we store an `InferenceData` as a netcdf then read the generated file\n",
    "as is through {func}`xarray.open_datatree`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a917dc64-3601-4b20-8353-b981f88f3855",
   "metadata": {},
   "outputs": [],
   "source": [
    "idata.to_netcdf(\"example.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64abc25b-2111-4c18-837c-41a8dac2c9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xarray import open_datatree\n",
    "dt = open_datatree(\"example.nc\")\n",
    "dt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708795ba-6d1c-41a2-bf87-ae92fe15076c",
   "metadata": {},
   "source": [
    "#### Other key differences\n",
    "`DataTree` supports an arbitrary level of nesting (as opposed to the exactly 1 level of nesting in\n",
    "`InferenceData`). Thus, to keep things consistent accessing its groups returns a `DataTree`,\n",
    "even if it is a leaf group. This means that `dt[\"posterior\"]` will now return a `DataTree`.\n",
    "In many cases this is irrelevant, but there will be some cases where you'll want the\n",
    "group as a `Dataset` instead. You can achieve this with `dt[\"posterior\"].dataset`.\n",
    "\n",
    "There are no changes at the variable/`DataArray` level. Thus, `dt[\"posterior\"][\"theta\"]` is still\n",
    "a `DataArray`, accessing its variables is one of the cases where having either `DataTree`\n",
    "or `Dataset` is irrelevant.\n",
    "\n",
    "### Enhanced converter flexibility\n",
    "Were you constantly needing to add an extra axis to your data because it didn't have any `chain` dimension? No more!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4defb20-059e-4f1e-b848-41251b176d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "rng = np.random.default_rng()\n",
    "data = rng.normal(size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a32f5d-c811-4277-b254-53b924ce61dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# arviz_legacy.from_dict({\"posterior\": {\"mu\": data}}) would fail\n",
    "# unless you did data[None, :] to add the chain dimension\n",
    "az.rcParams[\"data.sample_dims\"] = \"sample\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bee6e26-0601-4cb2-8f3a-7e17d849a47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = az.from_dict({\"posterior\": {\"mu\": data}})\n",
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5816596-a974-4fbb-aee8-88efaf7a84c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# arviz-stats and arviz-plots also take it into account\n",
    "az.plot_dist(dt);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488e6ecd-1269-4d98-8ae5-1a5e65531d32",
   "metadata": {},
   "source": [
    ":::{note}\n",
    "It is also possible to modify `sample_dims` through arguments to the different functions.\n",
    ":::\n",
    "\n",
    "### New data wrangling features\n",
    "We have also added multiple functions to help with common data wrangling tasks,\n",
    "mostly from and to `xarray.Dataset`. For example, you can convert a dataset\n",
    "to a wide format dataframe with unique combinations of `sample_dims` as its rows,\n",
    "with {func}`~arviz_base.dataset_to_dataframe`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59bc6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# back to default behaviour\n",
    "az.rcParams[\"data.sample_dims\"] = [\"chain\", \"draw\"]\n",
    "dt = az.load_arviz_data(\"centered_eight\")\n",
    "az.dataset_to_dataframe(dt.posterior.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d116a72b-a46b-4cac-959b-0b669ce7012f",
   "metadata": {},
   "source": [
    "Note it is also aware of ArviZ naming conventions in addition to using\n",
    "the `sample_dims` `rcParam`. It can be further customized through a `labeller` argument.\n",
    "\n",
    ":::{tip}\n",
    "If you want to convert to a long format dataframe, you should use\n",
    "{meth}`xarray.Dataset.to_dataframe` instead.\n",
    ":::\n",
    "\n",
    "## `arviz-stats`\n",
    "Stats and diagnostics related functionality have also had some changes,\n",
    "and it should also be noted that out of the 3 new modular libraries it is\n",
    "currently the one lagging behind a bit more. At the same time,\n",
    "it does already have several new features that won't be added to legacy ArviZ at any point,\n",
    "check out its {doc}`arviz_stats:api/index` page for the complete and up to date list\n",
    "of available functions.\n",
    "\n",
    "### Model comparison\n",
    "For a long time we have been recommending using PSIS-LOO-CV (`loo`) over WAIC.\n",
    "PSIS-LOO-CV is more robust, has better theoretical properties, and offers diagnostics\n",
    "to assess the reliability of the estimates. For these reasons, we have decided to remove WAIC\n",
    "from `arviz-stats`, and instead focus exclusively on PSIS-LOO-CV for model comparison.\n",
    "So now we offer many new features related to LOO. Including:\n",
    "- Compute weighted expectations, including mean, variance, quantiles, etc. See {func}`~arviz_stats.loo_expectations`.\n",
    "- Compute predictive metrics such as rmse, mae, etc. See {func}`~arviz_stats.loo_metrics`.\n",
    "- Compute CRPS/SCRPS, see {func}`~arviz_stats.loo_score`\n",
    "- Compute PSIS-LOO-CV for approximate posteriors. See {func}`~arviz_stats.loo_approximate_posterior`.\n",
    "\n",
    "\n",
    "For a complete list check {doc}`arviz_stats:api/index` and in particular {doc}`arviz_stats:api/index#model-comparison`\n",
    "\n",
    "\n",
    "### `dim` and `sample_dims`\n",
    "Similarly to the rest of the libraries, most functions take an argument to indicate\n",
    "which dimensions should be reduced (or considered core dims) in the different computations.\n",
    "Given `arviz-stats` is the one with behaviour and API closest to xarray itself,\n",
    "this argument can either be `dim` or `sample_dims` as a way to keep the APIs of ArviZ\n",
    "and xarray similar.\n",
    "\n",
    "Let's see the differences in action. `ess` uses `sample_dims`. This means we can do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8417aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = az.load_arviz_data(\"non_centered_eight\")\n",
    "az.ess(dt, sample_dims=[\"chain\", \"draw\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7324dc47",
   "metadata": {},
   "source": [
    "but we can't do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1985a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    az.ess(dt, sample_dims=[\"school\", \"draw\"])\n",
    "except Exception as err:\n",
    "    import traceback\n",
    "    traceback.print_exception(err)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632daeae",
   "metadata": {},
   "source": [
    "This limitation doesn't come from the fact that interpreting the \"school\" dimension as \"chain\"\n",
    "makes no sense but from the fact that when using `ess` on multiple variables (aka on a Dataset)\n",
    "all dimensions in `sample_dims` must be present in all variables.\n",
    "Consequently, the following cell is technically valid even if it still makes no sense conceptually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eef0abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.ess(dt, var_names=[\"theta\", \"theta_t\"], sample_dims=[\"school\", \"draw\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdca7fec",
   "metadata": {},
   "source": [
    "When we restrict the target variables to only \"theta\" and \"theta_t\" we make it so\n",
    "all variables have both \"school\" and \"draw\" dimension.\n",
    "\n",
    "All computations where it is required that input variables all have the full set of\n",
    "dimensions we want to operate on use `sample_dims`. On ArviZ's side this includes\n",
    "`ess`, `rhat` or `mcse`. Xarray only has an example of this:\n",
    "{meth}`~xarray.Dataset.to_stacked_array`.\n",
    "\n",
    "On the other hand, `hdi` uses `dim`. This means that both values we attempted\n",
    "for `sample_dims` with `ess` are valid without caveats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9095c5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.azstats.hdi(dim=[\"chain\", \"draw\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59f7a66",
   "metadata": {},
   "source": [
    "here we have reduced both \"chain\" and \"draw\" dimensions like we did in `ess`.\n",
    "The only difference is `hdi` also adds a \"ci_bound\" dimension, so instead\n",
    "of ending up with scalars and variables with a \"school\" dimension only,\n",
    "we end up with variables that have either \"ci_bound\" or (\"ci_bound\", \"school\") dimensionality.\n",
    "\n",
    "Let's continue with the other example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8cf6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.azstats.hdi(dim=[\"school\", \"draw\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4082a639",
   "metadata": {},
   "source": [
    "We are now reducing the subset of `dim` present in each variable. That means\n",
    "that `mu` and `tau` only have the \"draw\" dimension reduced, whereas `theta` and `theta_t`\n",
    "have both \"draw\" and \"school\" reduced. Consequently, all variables end up with \n",
    "(\"chain\", \"ci_bound\") dimensions.\n",
    "\n",
    "All computations where operating over different subsets of the provided dimensions makes\n",
    "sense use `dim`. On ArviZ's side this includes functions like `hdi`, `eti` or `kde`.\n",
    "Most xarray functions fall in this category too, some examples are {meth}`~xarray.Dataset.mean`,\n",
    "{meth}`~xarray.Dataset.quantile`, {meth}`~xarray.Dataset.std` or {meth}`~xarray.Dataset.cumsum`.\n",
    "\n",
    "### Accessors on xarray objects\n",
    "We are also taking advantage of the fact that xarray allows third party libraries to register\n",
    "accessors on its object. This means that _after importing `arviz_stats`_ (or a library that imports\n",
    "it like `arviz.preview`) DataArrays, Datasets and DataTrees get a new attribute, `azstats`.\n",
    "This attribute is called accessor and exposes ArviZ functions that act on the object from which\n",
    "the accessor is used.\n",
    "\n",
    "We plan to have most functions available as both top level functions and accessors to help\n",
    "with discoverability of ArviZ functions. But not all functions can be implemented as\n",
    "accessors to all objects. Mainly, functions that need multiple groups can be available\n",
    "on the DataTree accessor, but not on Dataset or DataArray ones. Moreover, at the time of\n",
    "writing, some functions are only available as one of the two options but should be extended soon.\n",
    "\n",
    "We have already used the `azstats` accessor to compute the HDI, now we can check that\n",
    "we get the same result when using `ess` through the accessor than what we got when using\n",
    "the top level function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6e5b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.azstats.ess()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6328b1f",
   "metadata": {},
   "source": [
    "### Computational backends\n",
    "We have also modified a bit how computations accelerated by optional dependencies are handled.\n",
    "There are no longer dedicated \"flag classes\" like we had for Numba and Dask. Instead,\n",
    "low level stats functions are implemented in classes so we can subclass and reimplement only\n",
    "bottleneck computations (with the rest of the computations being inherited from the base class).\n",
    "\n",
    "The default computational backend is controlled by `rcParams[\"stats.module\"]` which can be\n",
    "\"base\", \"numba\" or a user defined custom computational module[^2]. \n",
    "\n",
    "[^2]: User defined modules are valid when doing `rcParams[\"stats.module\"] = module` but can't\n",
    "    can't be set as the default through the `arvizrc` configuration file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04dfa78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = az.load_arviz_data(\"radon\")\n",
    "az.rcParams[\"stats.module\"] = \"base\"\n",
    "%timeit dt.azstats.histogram(dim=\"draw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4ae822",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.rcParams[\"stats.module\"] = \"numba\"\n",
    "%timeit dt.azstats.histogram(dim=\"draw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860cbf1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.rcParams[\"stats.module\"] = \"base\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8360d49d",
   "metadata": {},
   "source": [
    "The histogram method is one of the re-implemented ones, mostly so it scales better to larger data.\n",
    "However, it should be noted that we haven't really done much profiling nor in-depth optimization\n",
    "efforts. Please open issues if you notice performance regressions or open issues/PRs to \n",
    "discuss and implement faster versions of the bottleneck methods.\n",
    "\n",
    "### Array interface\n",
    "It is also possible to install `arviz-stats` without xarray or `arviz-base` in which case,\n",
    "only a subset of the functionality is available, and through an array only API.\n",
    "This API has little to no defaults or assumptions baked into it, leaving all the choices\n",
    "to the user who has to be explicit in every call.\n",
    "\n",
    "Due to the dependencies\n",
    "needed to install this minimal version of `arviz-stats` being only NumPy and SciPy\n",
    "we hope it will be particularly useful to other developers.\n",
    "PPL developers can for example use `arviz-stats` for MCMC diagnostics without having to add\n",
    "xarray or pandas as dependencies of their library. This will ensure they are using\n",
    "tested and up to date versions of the diagnostics without having to implement or maintain\n",
    "them as part of the PPL itself.\n",
    "\n",
    "The array interface is covered in detail at the {ref}`arviz_stats:array_interface` page."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13df89cf",
   "metadata": {},
   "source": [
    "## `arviz-plots`\n",
    "\n",
    "Out of the 3 libraries, `arviz-plots` is the one with the most changes at all levels,\n",
    "breaking changes, new features more layers to explore.\n",
    "\n",
    "### More and better supported backends!\n",
    "One of they key efforts of the refactor has been simplifying the way we interface\n",
    "with the different plotting backends supported.\n",
    "arviz-plots has more backends: matplotlib, bokeh and plotly are all supported now,\n",
    "with (mostly) feature parity among them. All while having less backend related code!\n",
    "\n",
    "This also means that `az.style` is no longer an alias to `matplotlib.style` but its own\n",
    "module with similar (reduced API) that sets the style for all compatible and installed\n",
    "backends (unless a backend is requested explicitly):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1da7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.style.use(\"arviz-vibrant\")\n",
    "dt = az.load_arviz_data(\"centered_eight\")\n",
    "az.plot_rank(dt, var_names=[\"mu\", \"tau\"], backend=\"matplotlib\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffc0108",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.io as pio\n",
    "pio.renderers.default = \"notebook\"\n",
    "pc = az.plot_rank(dt, var_names=[\"mu\", \"tau\"], backend=\"plotly\")\n",
    "pc.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b202d560",
   "metadata": {},
   "source": [
    "At the time of writing, there are three cross-backend themes defined by ArviZ:\n",
    "`arviz-variat`, `arviz-vibrant` and `arviz-cetrino`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9416392",
   "metadata": {},
   "source": [
    "### Plotting function inventory\n",
    "\n",
    "The following functions have been renamed or restructured:\n",
    "\n",
    "|   ArviZ <1       |   ArviZ >=1       |\n",
    "|------------------|-------------------|\n",
    "| plot_bpv                     | plot_ppc_pit, plot_ppc_tstat     |\n",
    "| plot_dist_comparison         | plot_prior_posterior             |\n",
    "| plot_ecdf                    | plot_dist, plot_ecdf_pit         |\n",
    "| plot_ess                     | plot_ess, plot_ess_evolution     |\n",
    "| plot_forest                  | plot_forest, plot_ridge          |\n",
    "| plot_ppc                     | plot_ppc_dist                    |\n",
    "| plot_posterior, plot_density | plot_dist                        |\n",
    "| plot_trace                   | plot_trace_dist, plot_trace_rank |\n",
    "\n",
    "Others have had their code rewritten and their arguments updated to some extent,\n",
    "but kept the same name:\n",
    "\n",
    "* plot_autocorr\n",
    "* plot_bf\n",
    "* plot_compare\n",
    "* plot_energy\n",
    "* plot_lm\n",
    "* plot_loo_pit\n",
    "* plot_mcse\n",
    "* plot_pair\n",
    "* plot_parallel\n",
    "* plot_rank\n",
    "\n",
    "The following functions have been added:\n",
    "\n",
    "* {func}`~arviz_plots.combine_plots`\n",
    "* {func}`~arviz_plots.plot_convergence_dist`\n",
    "* {func}`~arviz_plots.plot_pair_focus`\n",
    "* {func}`~arviz_plots.plot_ppc_interval`\n",
    "* {func}`~arviz_plots.plot_ppc_pava`\n",
    "* {func}`~arviz_plots.plot_ppc_rootogram`\n",
    "* {func}`~arviz_plots.plot_psense_dist`\n",
    "* {func}`~arviz_plots.plot_psense_quantities`\n",
    "* {func}`~arviz_plots.plot_trace`\n",
    "\n",
    "Some functions have been removed and we don't plan to add them:\n",
    "\n",
    "* plot_dist (notice we have `plot_dist` but it is a different function)\n",
    "* plot_kde (this is now part of `plot_dist`)\n",
    "* plot_violin\n",
    "\n",
    "And there are also functions we plan to add but aren't available yet.\n",
    "\n",
    "* plot_elpd\n",
    "* plot_khat\n",
    "* plot_ppc_censored\n",
    "* plot_ppc_residuals\n",
    "* plot_ts\n",
    "\n",
    ":::{note}\n",
    "For now, the documentation for arviz-plots defaults to `latest` which is built\n",
    "from GitHub with each commit. If you see some of the functions in the last block already\n",
    "on the example gallery you should be able to try them, but only if you install\n",
    "the development version! See {ref}`arviz_plots:installation`\n",
    ":::\n",
    "\n",
    "You can see all of them at the {ref}`arviz-plots gallery <arviz_plots:example_gallery>`.\n",
    "\n",
    "### What to expect from the new plotting functions\n",
    "\n",
    "There are two main differences with the plotting functions here in legacy ArviZ:\n",
    "\n",
    "1. The way of forwarding arguments to the plotting backends.\n",
    "2. The return type is now {class}`PlotCollection`, one of the key features of `arviz-plots`.\n",
    "   A quick overview in the context of `plot_xyz` is given here but it later has a section of\n",
    "   its own.\n",
    "\n",
    "Other than that, some arguments have been renamed or gotten different defaults,\n",
    "but nothing major. Note, however, that we have incorporated elements\n",
    "from grammar of graphics into `arviz-plots`, now that we'll cover the internals\n",
    "of `plot_xyz` in passing we'll use some terms from grammar of graphics.\n",
    "If you have never heard about grammar of graphics we recommend you take\n",
    "a look at {ref}`arviz_plots:overview_plots` before continuing.\n",
    "\n",
    "#### kwarg forwarding\n",
    "Most `plot_xyz` functions now have a `visuals` and a `stats` argument. These arguments\n",
    "are dictionaries whose keys define where their values are forwarded too. The values\n",
    "are also dictionaries representing keyword arguments that will be passed downstream\n",
    "via `**kwargs`. This allows you to send arbitrary keyword arguments to all the different\n",
    "visual elements or statistical computations that are part of a plot without\n",
    "bloating the call signature with endless `xyz_kwargs` arguments like in legacy ArviZ.\n",
    "\n",
    "These same arguments also allow indicating a visual element should not be added to the plot,\n",
    "or providing pre computed statistical summaries for faster re-rendering of plots (at the time\n",
    "of writing pre-computed inputs are only working in `plot_forest` but should be extended soon).\n",
    "\n",
    "In addition, the call signature of new plotting functions is `plot_xyz(..., **pc_kwargs)`,\n",
    "with these `pc_kwargs` being forwarded to the initialization of {class}`PlotCollection`.\n",
    "This argument allows controlling the layout of the {term}`arviz_plots:figure` as well\n",
    "as any {term}`arviz_plots:aesthetic mappings` that might be used by the plotting function.\n",
    "\n",
    "For a complete notebook introduction on this see {ref}`arviz_plots:plots_intro`\n",
    "\n",
    "#### New return type: `PlotCollection`\n",
    "All `plot_xyz` functions now return a \"plotting manager class\". At the time of writing\n",
    "this means either {class}`~arviz_plots.PlotCollection` (vast majority of plots) or\n",
    "{class}`PlotMatrix` (for upcoming `plot_pair` for example).\n",
    "\n",
    "These classes are the ones that handle {term}`arviz_plots:faceting` and\n",
    "{term}`arviz_plots:aesthetic mappings` and allow the `plot_xyz` functions to\n",
    "focus on the {term}`arviz_plots:visuals` and not on the plot layout or encodings.\n",
    "\n",
    "See {ref}`arviz_plots:use_plotcollection` for more details on how to work with\n",
    "existing `PlotCollection` instances.\n",
    "\n",
    "### Plotting manager classes\n",
    "As we have just mentioned, `plot_xyz` use these plotting manager classes and then return them\n",
    "as their output. In addition, we hope users will use these classes directly to help them\n",
    "write custom plotting functions more easily and with more flexibility.\n",
    "\n",
    "By using these classes, users should be able to focus on writing smaller functions that take\n",
    "care of a \"unit of plotting\". You can then use their `.map` methods to apply these plotting\n",
    "functions as many times as needed given the faceting and aesthetic mappings defined by the user.\n",
    "Different layouts and different mappings will generally not require changes to these plotting\n",
    "functions, only to the arguments that define aesthetic mappings and the faceting strategy.\n",
    "\n",
    "Take a look at {ref}`arviz_plots:compose_own_plot` if that sounds interesting!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d08e071",
   "metadata": {},
   "source": [
    "### Other arviz-plots features\n",
    "There are also helper functions to help compose or extend existing plotting functions.\n",
    "For example, we can create a new plot, with a similar layout to that of `plot_trace_dist`\n",
    "or `plot_rank_dist` but custom diagnostics in each column: distribution, rank and ess evolution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a862f196-0315-4d55-baf3-9e76fd86df8d",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "az.combine_plots(\n",
    "    dt,\n",
    "    [\n",
    "        (az.plot_dist, {\"kind\": \"ecdf\"}),\n",
    "        (az.plot_rank, {}),\n",
    "        (az.plot_ess_evolution, {}),\n",
    "    ],\n",
    "    var_names=[\"theta\", \"mu\", \"tau\"],\n",
    "    coords={\"school\": [\"Hotchkiss\", \"St. Paul's\"]},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4e2e85",
   "metadata": {},
   "source": [
    "## Other nice features\n",
    "\n",
    "### Citation helper\n",
    "\n",
    "We have also added a helper to cite ArviZ in your publications and also the methods implemented in it.\n",
    "You can get the citation in bibtex format through {func}`~arviz.citation`:\n",
    "\n",
    "### Extended documentation\n",
    "\n",
    "One recurring feedback we have received is that the documentation was ok for people very familiar with Bayesian statistics and probabilistic programming,\n",
    "but not so much for newcomers. Thus, we have added more introductory material and examples to the documentation, including a separated resource that show how to use ArviZ \"in-context\", see [EABM](https://arviz-devs.github.io/EABM/). And we attempted to make the documentation easier to nagivate and understand for everyone.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arviz_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
